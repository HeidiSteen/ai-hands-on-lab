{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Chunking\n",
    "\n",
    "The search solution is comprised of both **ingestion** and **retrieval**. One does not exist without the other.\n",
    "\n",
    "While the other experiments are focused on data retrieval, ingestion plays equal importance in the effectiveness of the search solution.\n",
    "\n",
    "Certain aspects of data ingestion need to be experimented as part of the experimentation phase:\n",
    "\n",
    "```{note}\n",
    "Other pre and post-processing techniques include: Optical Character Recognition, data conversation, use of Azure Form Recognizer to extract information from the documents, chunking, summarization, post-processing to make data more \"human like\", video captioning, speech to text, tagging, etc. are all methods that need to be considered and experimented with as part of the ingestion pipeline experimentation.\n",
    "```\n",
    "\n",
    "https://github.com/microsoft/rag-openai/blob/main/topics/RAG_EnablingSearch.md#learnings-from-engagements-1\n",
    "\n",
    "When processing data, splitting the source documents into chunks requires care and expertise to ensure the resulting chunks are small enough to be effective during fact retrieval but not too small so that enough context is provided during summarization.\n",
    "\n",
    "```{note}\n",
    "Our goal here is not to identify which chunking strategy is the “best” in general but rather to demonstrate how various choices of chunking may have a non-trivial impact on the ultimate outcome from the retrieval-augmented-generation solution.\n",
    "```\n",
    "\n",
    "<!-- https://vectara.com/blog/grounded-generation-done-right-chunking/#:~:text=In%20the%20context%20of%20Grounded%20Generation%2C%20chunking%20is,find%20natural%20segments%20like%20complete%20sentences%20or%20paragraphs. -->\n",
    "\n",
    "## Why Chunking Size Matters\n",
    "\n",
    "As mentioned [here](https://learn.microsoft.com/en-us/azure/search/semantic-search-overview), the models used to generate embedding vectors have maximum limits on the text fragments provided as input. For example, the maximum length of input text for the Azure OpenAI embedding models is **8,191** tokens. Given that each token is around 4 characters of text for common OpenAI models, this maximum limit is equivalent to around 6000 words of text. If you're using these models to generate embeddings, it's critical that the input text stays under the limit. Partitioning your content into chunks ensures that your data can be processed by the Large Language Models (LLM) used for indexing and queries.\n",
    "\n",
    "**Relevance and Granularity**: A small chunk size, like 128, yields more granular chunks. This granularity, however, presents a risk: vital information might not be among the top retrieved chunks, especially if the similarity _top_k_ setting is as restrictive as 2. Conversely, a chunk size of 512 is likely to encompass all necessary information within the top chunks, ensuring that answers to queries are readily available. To navigate this, we employ the _Faithfulness and Relevancy_ metrics. These measure the absence of ‘hallucinations’ and the ‘relevancy’ of responses based on the query and the retrieved contexts respectively.\n",
    "\n",
    "**Response Generation Time**: As the chunk_size increases, so does the volume of information directed into the LLM to generate an answer. While this can ensure a more comprehensive context, it might also slow down the system. Ensuring that the added depth doesn't compromise the system's responsiveness is crucial.\n",
    "\n",
    "In essence, determining the optimal chunk_size is about striking a balance: capturing all essential information without sacrificing speed. It's vital to undergo thorough testing with various sizes to find a configuration that suits the specific use case and dataset.\n",
    "\n",
    "https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5\n",
    "\n",
    "Example code: https://github.com/Azure/azure-search-vector-samples/blob/main/demo-python/code/data-chunking/textsplit-data-chunking-example.ipynb\n",
    "\n",
    "Read [Common Chunking Technique](https://learn.microsoft.com/en-us/azure/search/semantic-search-overview), [Content overlap considerations](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents#content-overlap-considerations), [Simple example of how to create chunks with sentences](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents#content-overlap-considerations)\n",
    "\n",
    "CODE: https://github.com/microsoft/rag-openai/blob/438999a5470bef7946fa1c8714ed1090e1ed40c3/samples/searchEvaluation/customskills/utils/chunker/text_chunker.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community==0.0.18Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached langchain_community-0.0.18-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community==0.0.18) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community==0.0.18) (2.0.25)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community==0.0.18)\n",
      "  Downloading aiohttp-3.9.3-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.0.18)\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.19 (from langchain-community==0.0.18)\n",
      "  Using cached langchain_core-0.1.22-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain-community==0.0.18)\n",
      "  Downloading langsmith-0.0.90-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community==0.0.18) (1.26.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community==0.0.18) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain-community==0.0.18)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.18)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.18) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.18)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.18)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.18)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.18)\n",
      "  Using cached marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.18)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting anyio<5,>=3 (from langchain-core<0.2,>=0.1.19->langchain-community==0.0.18)\n",
      "  Using cached anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2,>=0.1.19->langchain-community==0.0.18)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain-community==0.0.18)\n",
      "  Using cached langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.2,>=0.1.19->langchain-community==0.0.18) (23.2)\n",
      "Collecting pydantic<3,>=1 (from langchain-core<0.2,>=0.1.19->langchain-community==0.0.18)\n",
      "  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\n",
      "     ---------------------------------------- 0.0/83.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 83.5/83.5 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.18) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.18) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.18) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.18) (2023.11.17)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.18) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.18) (3.0.3)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3->langchain-core<0.2,>=0.1.19->langchain-community==0.0.18)\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.19->langchain-community==0.0.18)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain-core<0.2,>=0.1.19->langchain-community==0.0.18)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.2 (from pydantic<3,>=1->langchain-core<0.2,>=0.1.19->langchain-community==0.0.18)\n",
      "  Downloading pydantic_core-2.16.2-cp312-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.18)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached langchain_community-0.0.18-py3-none-any.whl (1.6 MB)\n",
      "Downloading aiohttp-3.9.3-cp312-cp312-win_amd64.whl (363 kB)\n",
      "   ---------------------------------------- 0.0/363.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 363.4/363.4 kB 22.1 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Using cached langchain_core-0.1.22-py3-none-any.whl (239 kB)\n",
      "Using cached langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB ? eta 0:00:00\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "   ---------------------------------------- 0.0/394.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 394.8/394.8 kB 25.6 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.16.2-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 1.3/1.9 MB 27.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 29.7 MB/s eta 0:00:00\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.4/76.4 kB 4.1 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Installing collected packages: tenacity, sniffio, pydantic-core, mypy-extensions, multidict, marshmallow, jsonpointer, frozenlist, annotated-types, yarl, typing-inspect, pydantic, jsonpatch, anyio, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-community\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.2.0 dataclasses-json-0.6.4 frozenlist-1.4.1 jsonpatch-1.33 jsonpointer-2.4 langchain-community-0.0.18 langchain-core-0.1.22 langsmith-0.0.87 marshmallow-3.20.2 multidict-6.0.5 mypy-extensions-1.0.0 pydantic-2.6.1 pydantic-core-2.16.2 sniffio-1.3.0 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following yanked versions: 0.8.3, 0.10.19.dev18\n",
      "ERROR: Ignored the following versions that require a different python version: 0.12.0 Requires-Python >=3.9.0,<3.12; 0.12.2 Requires-Python >=3.9.0,<3.12; 0.12.3 Requires-Python >=3.9.0,<3.12; 0.12.4 Requires-Python >=3.9.0,<3.12\n",
      "ERROR: Could not find a version that satisfies the requirement unstructured==0.12.3 (from versions: 0.0.1.dev0, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.5, 0.2.6.dev1, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.5, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.6, 0.4.7, 0.4.8, 0.4.9, 0.4.10, 0.4.11, 0.4.12, 0.4.13, 0.4.14, 0.4.15, 0.4.16, 0.5.0, 0.5.1, 0.5.2, 0.5.3, 0.5.4, 0.5.6, 0.5.7, 0.5.8, 0.5.9, 0.5.10, 0.5.11, 0.5.12, 0.5.13, 0.6.0, 0.6.1, 0.6.2, 0.6.3, 0.6.4, 0.6.5, 0.6.6, 0.6.7, 0.6.8, 0.6.9, 0.6.10, 0.6.11, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.7.7, 0.7.8, 0.7.9, 0.7.10, 0.7.11, 0.7.12, 0.8.0, 0.8.1, 0.8.4, 0.8.5, 0.8.6, 0.8.7, 0.8.8, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.10.0, 0.10.1, 0.10.2, 0.10.4, 0.10.5, 0.10.6, 0.10.7, 0.10.8, 0.10.9, 0.10.10, 0.10.11, 0.10.12, 0.10.13, 0.10.14, 0.10.15, 0.10.16, 0.10.18, 0.10.19, 0.10.20, 0.10.21, 0.10.22, 0.10.23, 0.10.24, 0.10.25, 0.10.26, 0.10.27, 0.10.28, 0.10.29, 0.10.30, 0.11.0, 0.11.1, 0.11.2, 0.11.4, 0.11.5, 0.11.6, 0.11.7, 0.11.8)\n",
      "ERROR: No matching distribution found for unstructured==0.12.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured-client==0.17.0\n",
      "  Using cached unstructured_client-0.17.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer>=3.2.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (3.3.2)\n",
      "Collecting dataclasses-json-speakeasy>=0.5.11 (from unstructured-client==0.17.0)\n",
      "  Using cached dataclasses_json_speakeasy-0.5.11-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: idna>=3.4 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (3.6)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client==0.17.0)\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: marshmallow>=3.19.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (3.20.2)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (1.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (2.31.0)\n",
      "Requirement already satisfied: six>=1.16.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (1.16.0)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7.1 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (4.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26.18 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from unstructured-client==0.17.0) (2.1.0)\n",
      "Using cached unstructured_client-0.17.0-py3-none-any.whl (20 kB)\n",
      "Using cached dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: jsonpath-python, dataclasses-json-speakeasy, unstructured-client\n",
      "Successfully installed dataclasses-json-speakeasy-0.5.11 jsonpath-python-1.0.6 unstructured-client-0.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.5\n",
      "  Using cached langchain-0.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.17 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (0.0.18)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (0.1.22)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain==0.1.5) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.5) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.5) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.5) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain==0.1.5) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain==0.1.5) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.5) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.5) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.5) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain==0.1.5) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain==0.1.5) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain==0.1.5) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain==0.1.5) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.5) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.5) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\adnegrau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.5) (1.0.0)\n",
      "Using cached langchain-0.1.5-py3-none-any.whl (806 kB)\n",
      "Installing collected packages: langchain\n",
      "Successfully installed langchain-0.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-community==0.0.18\n",
    "# %pip install langchain-core==0.1.20\n",
    "%pip install unstructured==0.12.3\n",
    "%pip install unstructured-client==0.17.0\n",
    "%pip install langchain==0.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredMarkdownLoader, UnstructuredFileLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import glob\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader, UnstructuredFileLoader\n",
    "from langchain.text_splitter import MarkdownTextSplitter, NLTKTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "# Code also https://github.com/microsoft/rag-openai/blob/438999a5470bef7946fa1c8714ed1090e1ed40c3/samples/searchEvaluation/customskills/utils/chunker/text_chunker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"unstructured[md]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents_from_folder(path: str) -> list[str]:\n",
    "    print(\"Loading documents...\")\n",
    "    markdown_documents = []\n",
    "    for file in tqdm.tqdm(glob.glob(path, recursive=True)):\n",
    "        loader = UnstructuredFileLoader(file) \n",
    "        document = loader.load()\n",
    "        markdown_documents.append(document)\n",
    "    return markdown_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 777/777 [00:57<00:00, 13.57it/s]\n"
     ]
    }
   ],
   "source": [
    "markdown_documents = load_documents_from_folder(\"../data/docs/**/*.md\")\n",
    "# TODO: Move this to a Storage Account?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(documents: list) -> list:\n",
    "    print(\"Creating chunks...\")\n",
    "    markdown_splitter = MarkdownTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=300, chunk_overlap=30\n",
    "    )\n",
    "    lengths = {}\n",
    "    all_chunks = {}\n",
    "    chunk_id = 0\n",
    "    for document in tqdm.tqdm(documents):\n",
    "        current_chunks_text_list = markdown_splitter.split_text(\n",
    "            document[0].page_content\n",
    "        )  # output = [\"content chunk1\", \"content chunk2\", ...]\n",
    "\n",
    "        for i, chunk in enumerate(\n",
    "            current_chunks_text_list\n",
    "        ):  # (0, \"content chunk1\"), (1, \"content chunk2\"), ...\n",
    "            current_chunk_dict = {\n",
    "                \"chunk_id\": i,\n",
    "                \"chunk_text\": chunk,\n",
    "                \"source\": document[0].metadata[\"source\"],\n",
    "            }\n",
    "            current_id_str = f\"chunk{chunk_id}_{i}\"\n",
    "            all_chunks[current_id_str] = current_chunk_dict\n",
    "\n",
    "        chunk_id += 1\n",
    "\n",
    "        n_chunks = len(current_chunks_text_list)\n",
    "        # lengths = {[Number of chunks]: [number of documents with that number of chunks]}\n",
    "        if n_chunks not in lengths:\n",
    "            lengths[n_chunks] = 1\n",
    "        else:\n",
    "            lengths[n_chunks] += 1\n",
    "\n",
    "    print(lengths)\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 777/777 [00:02<00:00, 277.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 145, 2: 137, 4: 69, 5: 74, 7: 43, 12: 8, 16: 6, 32: 1, 18: 7, 3: 98, 8: 30, 6: 58, 20: 2, 9: 20, 13: 13, 15: 10, 10: 11, 17: 2, 11: 19, 14: 12, 43: 1, 25: 1, 26: 2, 22: 3, 30: 1, 19: 2, 38: 1, 29: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunks = create_chunks(markdown_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we will use OpenAI ada for embedding the chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload files to a storage account so we can create an Indexer\n",
    "https://github.com/microsoft/rag-openai/blob/438999a5470bef7946fa1c8714ed1090e1ed40c3/samples/searchEvaluation/upload_files.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: python-dotenv in c:\\projects\\workshop2024\\.venv\\lib\\site-packages (1.0.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'workspace_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m STORAGE_ACCOUNT_URL \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworkspace_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_upload_ops_files\u001b[39m(credential: AzureCliCredential, storage_account_name: \u001b[38;5;28mstr\u001b[39m, folder: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m      4\u001b[0m     path \u001b[38;5;241m=\u001b[39m ROOT_FILE_DIR \u001b[38;5;241m/\u001b[39m folder\n",
      "File \u001b[1;32m<frozen os>:679\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'workspace_name'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}