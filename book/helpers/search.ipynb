{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "%reload_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import (\n",
    "    VectorizedQuery\n",
    ")\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    ScoringProfile,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearch,\n",
    "    HnswParameters,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    ")\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "import os.path\n",
    "\n",
    "# subscription_id = os.environ[\"subscription_id\"]\n",
    "# resource_group_name = os.environ[\"resource_group_name\"]\n",
    "# workspace_name = os.environ[\"workspace_name\"]\n",
    "service_endpoint = os.environ[\n",
    "    \"service_endpoint\"\n",
    "]  # the endpoint of your Azure Cognitive Search service\n",
    "key = os.environ[\"search_key\"]\n",
    "\n",
    "# aoai_connection_name = os.environ['aoai_connection_name']\n",
    "aoi_deployment_name = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "aoi_api_key = os.environ[\"aoi_api_key\"]\n",
    "aoai_endpoint = os.environ[\"aoai_endpoint\"]\n",
    "embedding_model_name = os.environ[\"embeddingModelName\"]\n",
    "\n",
    "search_index_name = \"index_chunks_2\"\n",
    "search_index_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "credential = AzureKeyCredential(key)\n",
    "storage_account_connection_string = os.getenv(\"storage_account_connection_string\")\n",
    "embeddingModelName = os.getenv(\"embeddingModelName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Index Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(search_index_name):\n",
    "    client = SearchIndexClient(service_endpoint, AzureKeyCredential(key))\n",
    "\n",
    "    # 1. Define the fields\n",
    "    fields = [\n",
    "        SimpleField(\n",
    "            name=\"chunkId\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            sortable=True,\n",
    "            filterable=True,\n",
    "            key=True,\n",
    "        ),\n",
    "        SimpleField(\n",
    "            name=\"source\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            sortable=True,\n",
    "            filterable=True,\n",
    "        ),\n",
    "        SearchableField(name=\"chunkContent\", type=SearchFieldDataType.String),\n",
    "        SearchField(\n",
    "            name=\"chunkContentVector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=1536,  # the dimension of the embedded vector\n",
    "            vector_search_profile_name=\"my-vector-config\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # 2. Configure the vector search configuration\n",
    "    vector_search = VectorSearch(\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"my-vector-config\",\n",
    "                algorithm_configuration_name=\"my-algorithms-config\"\n",
    "            )\n",
    "        ],\n",
    "        algorithms=[\n",
    "            # Contains configuration options specific to the hnsw approximate nearest neighbors  algorithm used during indexing and querying\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"my-algorithms-config\",\n",
    "                kind=\"hnsw\",\n",
    "                # https://learn.microsoft.com/en-us/python/api/azure-search-documents/azure.search.documents.indexes.models.hnswparameters?view=azure-python-preview#variables\n",
    "                parameters=HnswParameters(\n",
    "                    m=4,\n",
    "                    # The size of the dynamic list containing the nearest neighbors, which is used during index time.\n",
    "                    # Increasing this parameter may improve index quality, at the expense of increased indexing time.\n",
    "                    ef_construction=400,\n",
    "                    # The size of the dynamic list containing the nearest neighbors, which is used during search time.\n",
    "                    # Increasing this parameter may improve search results, at the expense of slower search.\n",
    "                    ef_search=500,\n",
    "                    # The similarity metric to use for vector comparisons.\n",
    "                    # Known values are: \"cosine\", \"euclidean\", and \"dotProduct\"\n",
    "                    metric=\"cosine\",\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    index = SearchIndex(\n",
    "        name=search_index_name,\n",
    "        fields=fields,\n",
    "        vector_search=vector_search,\n",
    "    )\n",
    "\n",
    "    result = client.create_or_update_index(index)\n",
    "    print(f\"Index: '{result.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_query_embedding(\n",
    "    query,\n",
    "    endpoint=aoai_endpoint,\n",
    "    api_key=aoi_api_key,\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    embedding_model_deployment=embedding_model_name,\n",
    "):\n",
    "    request_url = f\"{endpoint}/openai/deployments/{embedding_model_deployment}/embeddings?api-version={api_version}\"\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": api_key}\n",
    "    request_payload = {\"input\": query}\n",
    "    embedding_response = requests.post(\n",
    "        request_url, json=request_payload, headers=headers, timeout=None\n",
    "    )\n",
    "    if embedding_response.status_code == 200:\n",
    "        data_values = embedding_response.json()[\"data\"]\n",
    "        embeddings_vectors = [data_value[\"embedding\"] for data_value in data_values]\n",
    "        return embeddings_vectors\n",
    "    else:\n",
    "        raise Exception(f\"failed to get embedding: {embedding_response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_for_chunks_and_save_to_file(path_to_chunks_file, path_to_output):\n",
    "    # path_to_file = f\"./output/chunks-solution-ops-embedded-{totalNumberOfDocuments}.json\"\n",
    "    if(os.path.exists(path_to_chunks_file)):\n",
    "        print(f\"Embeddings were already created for chunked data at: {path_to_chunks_file} \")\n",
    "        return\n",
    "    with open(path_to_chunks_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        input_data = json.load(file)\n",
    "        for chunk in input_data:\n",
    "            content = chunk[\"chunkContent\"]\n",
    "            content_emebddings = get_query_embedding(content)[0]\n",
    "            chunk[\"chunkContentVector\"] = content_emebddings\n",
    "    print(f\"Created {len(input_data)} chunks\")\n",
    "    print(f\"Example of one chunk: {input_data[1]}\")\n",
    "\n",
    "    with open(path_to_output, \"w\") as f:\n",
    "        json.dump(input_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data to the Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Upload documents to the index\n",
    "def upload_data(file_path, search_index_name):\n",
    "    # f\"./output/chunks-solution-ops-embedded-{totalNumberOfDocuments}.json\"\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            documents = json.load(file)\n",
    "\n",
    "        search_client = SearchClient(\n",
    "            endpoint=service_endpoint, index_name=search_index_name, credential=credential\n",
    "        )\n",
    "        search_client.upload_documents(documents)\n",
    "        print(f\"Uploaded {len(documents)} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading documents: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
